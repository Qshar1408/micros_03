# Домашнее задание к занятию «Микросервисы: подходы»

### Грибанов Антон. FOPS-31.

Вы работаете в крупной компании, которая строит систему на основе микросервисной архитектуры.
Вам как DevOps-специалисту необходимо выдвинуть предложение по организации инфраструктуры для разработки и эксплуатации.


## Задача 1: Обеспечить разработку

Предложите решение для обеспечения процесса разработки: хранение исходного кода, непрерывная интеграция и непрерывная поставка. 
Решение может состоять из одного или нескольких программных продуктов и должно описывать способы и принципы их взаимодействия.

Решение должно соответствовать следующим требованиям:
- облачная система;
- система контроля версий Git;
- репозиторий на каждый сервис;
- запуск сборки по событию из системы контроля версий;
- запуск сборки по кнопке с указанием параметров;
- возможность привязать настройки к каждой сборке;
- возможность создания шаблонов для различных конфигураций сборок;
- возможность безопасного хранения секретных данных (пароли, ключи доступа);
- несколько конфигураций для сборки из одного репозитория;
- кастомные шаги при сборке;
- собственные докер-образы для сборки проектов;
- возможность развернуть агентов сборки на собственных серверах;
- возможность параллельного запуска нескольких сборок;
- возможность параллельного запуска тестов.

Обоснуйте свой выбор.

### Решение:

**Стек:** GitLab + GitLab Runner + HashiCorp Vault

**Схема работы:**
1. **GitLab** хранит код микросервисов (отдельный репозиторий на каждый сервис)
2. **GitLab CI/CD** автоматически запускает сборки при пуше кода
3. **Ручные сборки** с параметрами настраиваются через manual jobs в .gitlab-ci.yml
4. **Шаблоны сборок** создаются через include-шаблоны в YAML
5. **HashiCorp Vault** хранит секреты, интегрируется с пайплайнами
6. **GitLab Runner** на ваших серверах выполняет сборки
7. **Docker** обеспечивает изоляцию и кастомные образы для сборки

**Ключевые преимущества:**
- Единая платформа для кода и CI/CD
- Полный контроль над окружением сборки
- Параллельные сборки и тесты "из коробки"
- Безопасное хранение секретов
- Гибкость кастомизации через YAML

Решение покрывает все требования и масштабируется под нагрузки микросервисной архитектуры.


## Задача 2: Логи

Предложите решение для обеспечения сбора и анализа логов сервисов в микросервисной архитектуре.
Решение может состоять из одного или нескольких программных продуктов и должно описывать способы и принципы их взаимодействия.

Решение должно соответствовать следующим требованиям:
- сбор логов в центральное хранилище со всех хостов, обслуживающих систему;
- минимальные требования к приложениям, сбор логов из stdout;
- гарантированная доставка логов до центрального хранилища;
- обеспечение поиска и фильтрации по записям логов;
- обеспечение пользовательского интерфейса с возможностью предоставления доступа разработчикам для поиска по записям логов;
- возможность дать ссылку на сохранённый поиск по записям логов.

Обоснуйте свой выбор.

### Решение:

**Что используем:**
- **Fluentd** - сбор логов с серверов
- **Kafka** - надежная пересылка логов
- **Elasticsearch** - хранилище для поиска
- **Kibana** - веб-интерфейс для разработчиков

---

**Предполагаемая схема работы:**
```
Приложения → Fluentd → Kafka → Elasticsearch → Kibana
```

**Что делает каждый компонент:**

1. **Fluentd**
   - Собирает логи со всех серверов
   - Читает обычный вывод программ (stdout)
   - Работает как агент на каждом сервере

2. **Kafka** 
   - Буфер для надежности
   - Сохраняет логи если Elasticsearch недоступен
   - Гарантирует что логи не потеряются

3. **Elasticsearch**
   - Быстрый поиск по всем логам
   - Фильтрация по любым полям
   - Хранит историю логов

4. **Kibana**
   - Веб-интерфейс для разработчиков
   - Поиск как в Google: "ошибка 500 в сервисе платежей"
   - Сохранение поисков и ссылки на них

---

### Почему именно этот набор

   * **Просто для разработчиков** - пишут логи как обычно в консоль  
   * **Надежно** - логи не теряются даже при сбоях  
   * **Быстрый поиск** - находим нужные записи за секунды  
   * **Удобный интерфейс** - Kibana понятен без обучения  
   * **Масштабируется** - работает на 10 или 1000 сервисов  

**Пример поиска в Kibana:**
```
service:"payment" AND error:"timeout"
```
Можно сохранить этот поиск и дать ссылку коллегам.

Судя по опыту многих компаний - это стандартное решение, которое проверено и работает.


## Задача 3: Мониторинг

Предложите решение для обеспечения сбора и анализа состояния хостов и сервисов в микросервисной архитектуре.
Решение может состоять из одного или нескольких программных продуктов и должно описывать способы и принципы их взаимодействия.

Решение должно соответствовать следующим требованиям:
- сбор метрик со всех хостов, обслуживающих систему;
- сбор метрик состояния ресурсов хостов: CPU, RAM, HDD, Network;
- сбор метрик потребляемых ресурсов для каждого сервиса: CPU, RAM, HDD, Network;
- сбор метрик, специфичных для каждого сервиса;
- пользовательский интерфейс с возможностью делать запросы и агрегировать информацию;
- пользовательский интерфейс с возможностью настраивать различные панели для отслеживания состояния системы.

Обоснуйте свой выбор.

### Решение:

**Что используем:**
- **Prometheus** - сбор метрик
- **Grafana** - красивый интерфейс
- **Node Exporter** - метрики серверов
- **cAdvisor** - метрики контейнеров

---

### Как это работает

**Простая схема:**
```
Сервисы → Prometheus → Grafana
Серверы ↗
```

**Что делает каждый:**

1. **Prometheus**
   - Собирает цифры со всех серверов и сервисов
   - Хранит историю показателей
   - Сам находит что мониторить в Kubernetes

2. **Node Exporter**
   - Собирает данные о серверах:
   - CPU, память, диск, сеть
   - Работает на каждом сервере

3. **cAdvisor**
   - Показывает использование для каждого контейнера
   - Сколько CPU/RAM ест каждый сервис

4. **Grafana**
   - Красивые графики и дашборды
   - Поиск и фильтрация метрик
   - Можно настроить под себя

---

### Что можем отслеживать

**По серверам:**
- Загрузка процессора
- Свободная память
- Место на диске
- Сетевой трафик

**По сервисам:**
- Потребление CPU контейнером
- Использование памяти
- Количество запросов
- Время ответа

**Кастомные метрики:**
- Количество пользователей
- Ошибки в приложении
- Бизнес-показатели

---

### Почему этот выбор

   * **Просто** - Prometheus сам всё находит  
   * **Наглядно** - Grafana показывает всё на графиках  
   * **Гибко** - можно добавить любые метрики  
   * **Бесплатно** - всё открытое ПО  
   * **Стандарт** - используют все крупные компании  

**Пример:**
- Видим что сервис "платежи" жрет 80% CPU
- Находим медленные запросы
- Смотрим нагрузку на базу данных

Всё в одном месте - и для разработчиков, и для админов.

## Задача 4: Логи * (необязательная)

Продолжить работу по задаче API Gateway: сервисы, используемые в задаче, пишут логи в stdout. 

Добавить в систему сервисы для сбора логов Vector + ElasticSearch + Kibana со всех сервисов, обеспечивающих работу API.

### Результат выполнения: 

docker compose файл, запустив который можно перейти по адресу http://localhost:8081, по которому доступна Kibana.
Логин в Kibana должен быть admin, пароль qwerty123456.


## Задача 5: Мониторинг * (необязательная)

Продолжить работу по задаче API Gateway: сервисы, используемые в задаче, предоставляют набор метрик в формате prometheus:

- сервис security по адресу /metrics,
- сервис uploader по адресу /metrics,
- сервис storage (minio) по адресу /minio/v2/metrics/cluster.

Добавить в систему сервисы для сбора метрик (Prometheus и Grafana) со всех сервисов, обеспечивающих работу API.
Построить в Graphana dashboard, показывающий распределение запросов по сервисам.

### Результат выполнения: 

docker compose файл, запустив который можно перейти по адресу http://localhost:8081, по которому доступна Grafana с настроенным Dashboard.
Логин в Grafana должен быть admin, пароль qwerty123456.

---

### Как оформить ДЗ?

Выполненное домашнее задание пришлите ссылкой на .md-файл в вашем репозитории.
